# 🧠 TrustAIRepo

> Open-science repository for frameworks, taxonomies, and metrics that support the development of **Trustworthy Artificial Intelligence** systems.

---

## 🚀 About the Project

**TrustAIRepo** is a scientific initiative to structure, validate, and disseminate tools and methodologies that bring *trustworthiness* into the real-world design, development, and governance of AI systems.

It focuses on **sociotechnical frameworks** that enable the operationalization of high-level principles such as fairness, explicability, robustness, and lawfulness—across architectures, datasets, evaluation metrics, and system behavior.

The repository is aligned with the goals of regulatory frameworks like the **EU AI Act**, and emerging **AI auditing practices**.

> The first consolidated contribution of this repository is a **sociotechnical taxonomy of Trustworthy AI**, published in *Expert Systems with Applications* (Elsevier, 2025).

---
## 🧠 Trustworthy AI Taxonomy

We propose a **sociotechnical taxonomy** of Trustworthy AI that systematically organizes the key dimensions involved in the ethical, legal, and technical governance of intelligent systems. This taxonomy is designed as a **practical vehicle to operationalize high-level AI principles**, allowing practitioners to interpret abstract values in actionable and measurable terms.

The taxonomy is structured around **seven core principles**:

- **Lawfulness**: alignment with legal norms, rights, and regulatory requirements.
- **Beneficence**: promotion of individual and collective well-being.
- **Non-maleficence**: minimization of harm and unintended consequences.
- **Autonomy**: respect for human agency and meaningful control.
- **Justice**: fairness, inclusion, and mitigation of bias or discrimination.
- **Explicability**: transparency, interpretability, and communication of system behavior.
- **Technology**: reliability, robustness, resilience, and security of the underlying systems.

This taxonomy acts as a **translation layer** between abstract normative principles (such as those defined by the EU AI Act, UNESCO, OECD, or the AI4People framework) and the concrete components of AI system development. It enables:

- Systematic **assessment of trustworthiness gaps** in system design.
- Support for **compliance-by-design** in regulated domains.
- Structuring **documentation and audits** for algorithmic accountability.
- Guiding **evaluation criteria** for fairness, safety, and robustness.
- Anchoring multi-stakeholder discussions on AI governance and ethics.

The taxonomy has been applied or is being integrated into several research and development areas, such as,  **Design of trustworthy Retrieval-Augmented Generation (RAG)** architectures with explainability and verifiability layers or  **Fairness evaluation frameworks** in unsupervised security systems using extended independence/separation/sufficiency metrics. It is also intended to serve as a foundational layer in the development of **trust profiles**, **regulatory reporting systems**, and **trust certification criteria** for AI deployments in sensitive sectors such as finance, health, or public administration.


📄 **Read the full article in *Expert Systems with Applications* (Elsevier, 2025):**  
👉 [https://doi.org/10.1016/j.eswa.2025.128034](https://doi.org/10.1016/j.eswa.2025.128034)


## 📚 Citation

If you use this taxonomy or build upon it, please cite the following publication:

> Carlos Mario Braga, Manuel A. Serrano, and Eduardo Fernández-Medina.  
> *Towards a methodology for ethical artificial intelligence system development: A necessary trustworthiness taxonomy*.  
> Expert Systems with Applications, Vol. 286, 2025, 128034.  

```bibtex
@article{BRAGA2025128034,
  title     = {Towards a methodology for ethical artificial intelligence system development: A necessary trustworthiness taxonomy},
  author    = {Carlos Mario Braga and Manuel A. Serrano and Eduardo Fernández-Medina},
  journal   = {Expert Systems with Applications},
  volume    = {286},
  pages     = {128034},
  year      = {2025},
  doi       = {https://doi.org/10.1016/j.eswa.2025.128034},
  url       = {https://www.sciencedirect.com/science/article/pii/S0957417425016550}
}
```

## 📦 Coming Next

This repository will grow to include:

- 🔍 Trustworthiness-aware RAG architectures  
- 🧪 Experimental validation datasets and tools  
- 📊 Metric frameworks for fairness and robustness  
- 🤖 Trust governance agents and SDLC extensions

Stay tuned!

## 📫 Contact
If you have any questions or would like to discuss our research further, please feel free to contact us:
- [LinkedIn](https://www.linkedin.com/in/carlosmariobragabigdata/)
- Orcid : [0009-0009-2373-0990](https://orcid.org/0009-0009-2373-0990)
- [Email](CarlosMario.Braga1@alu.uclm.es)

## 💬 Inspirational Quote
> "To live effectively is to live with adequate information." (Norbert Wiener)

## 🎉 Acknowledgements
The initial development of this research was supported by several publicly funded research projects in Spain and the European Union, which are acknowledged in the original publication.

We thank all collaborators and institutions that contributed to the academic and technical foundations of this work.


Thank you for visiting our presentation page. We appreciate your interest in our research!

